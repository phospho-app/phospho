{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and Using a Custom Job with phospho Lab\n",
    "\n",
    "In this notebook, we are going to:\n",
    "- define our own job to be runned with phospho. In this example, it will be a regex text on the name of a city.\n",
    "- add it to our phopho lab workload\n",
    "- running this job on some messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"phospho[lab]\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our own REGEX job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phospho import lab\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "def my_custom_job(message: lab.Message, forbidden_words: List) -> lab.JobResult:\n",
    "    \"\"\"\n",
    "    For each each message, me will check if the forbidden words are present in the message.\n",
    "    The function will return a JobResult with a boolean value \n",
    "    (True if one of the words is present, False otherwise).\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = r'\\b(' + '|'.join(re.escape(word) for word in forbidden_words) + r')\\b'\n",
    "\n",
    "    # Use re.search() to check if any of the words are in the text\n",
    "    if re.search(pattern, message.content):\n",
    "        result = True\n",
    "    else:\n",
    "        result = False\n",
    "    \n",
    "    return lab.JobResult(\n",
    "        job_id=\"my_custom_job\",\n",
    "        result_type=lab.ResultType.bool,\n",
    "        value=result,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: True (expected: True)\n"
     ]
    }
   ],
   "source": [
    "# Let's test the function\n",
    "result = my_custom_job(lab.Message(content=\"I love my cat\", sender=\"user\"), [\"cat\", \"dog\"])\n",
    "print(f\"Result: {result.value} (expected: True)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding it to our lab workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a workload in our lab\n",
    "workload = lab.Workload()\n",
    "\n",
    "# Add our job to the workload\n",
    "workload.add_job(\n",
    "    lab.Job(\n",
    "        id=\"regex_check\",\n",
    "        job_function=my_custom_job, # We add our custom job function here\n",
    "        config=lab.JobConfig(\n",
    "            forbidden_words=[\"cat\", \"dog\"]\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is setup, we can run our job on messages and see if they match our regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In message 1, a forbidden word was detected: False\n",
      "In message 2, a forbidden word was detected: True\n",
      "In message 3, a forbidden word was detected: True\n"
     ]
    }
   ],
   "source": [
    "await workload.async_run(\n",
    "    messages=[\n",
    "        # No forbiden word is present.\n",
    "        lab.Message(\n",
    "            id=\"message_1\",\n",
    "            content=\"I like elephants.\",\n",
    "        ),\n",
    "        # One forbiden word is present.\n",
    "        lab.Message(\n",
    "            id=\"message_2\",\n",
    "            content=\"I love my cat.\",\n",
    "        ),\n",
    "        # Both forbidden words present.\n",
    "        lab.Message(\n",
    "            id=\"message_3\",\n",
    "            content=\"I love my cat and my dog.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Let's see the results\n",
    "for i in range(1, 4):\n",
    "    print(\n",
    "        f\"In message {i}, a forbidden word was detected: {workload.results['message_'+str(i)]['regex_check'].value}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the job on some messages generated by OpenAI GPT-3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and check env variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from phospho import config\n",
    "\n",
    "assert (\n",
    "    config.OPENAI_API_KEY is not None\n",
    "), \"You need to set the OPENAI_API_KEY environment variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First poem:\n",
      "In the heart of the forest deep and wild,\n",
      "Where creatures of all kinds roam free,\n",
      "There lies a beauty pure and undefiled,\n",
      "In the animals that dwell with glee.\n",
      "\n",
      "The graceful deer with eyes so kind,\n",
      "Mov...\n",
      "\n",
      "Second poem:\n",
      "In a world of wonder, where nature reigns,\n",
      "Among the creatures that roam the plains,\n",
      "The mighty lion with golden mane,\n",
      "Stalks his prey, a master of the game.\n",
      "\n",
      "The graceful dolphin in ocean's deep,\n",
      "Dan...\n",
      "\n",
      "Third poem:\n",
      "In a world where cats and dogs meet,\n",
      "A dance of harmony, so sweet.\n",
      "With whiskers twitching and tails wagging,\n",
      "Their friendship everlasting, never sagging.\n",
      "\n",
      "The cat, so sly and sleek and wise,\n",
      "Inquisit...\n"
     ]
    }
   ],
   "source": [
    "# Generate a poem about animals, let's see if the forbidden words are present\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=config.OPENAI_API_KEY)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a brilliant poet.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write me a poem about animals.\"},\n",
    "  ],\n",
    "  temperature=0.9,\n",
    ")\n",
    "\n",
    "poem_1 = completion.choices[0].message.content\n",
    "\n",
    "print(\"First poem:\")\n",
    "print(poem_1[:200] + \"...\" if len(poem_1) > 200 else poem_1)\n",
    "\n",
    "# Let's do another one, increasing the probability of the forbidden words\n",
    "# Actually have no idea if the forbidden words will be present\n",
    "# You can re-run this cell to get different results\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a brilliant poet.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write me a poem about animals. Name some animals.\"},\n",
    "  ],\n",
    "  temperature=0.9,\n",
    ")\n",
    "\n",
    "poem_2 = completion.choices[0].message.content\n",
    "\n",
    "print(\"\")\n",
    "print(\"Second poem:\")\n",
    "print(poem_2[:200] + \"...\" if len(poem_2) > 200 else poem_2)\n",
    "\n",
    "# Let's do a final one, where the forbidden words should be present\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a brilliant poet.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write me a poem about cat and dogs.\"},\n",
    "  ],\n",
    "  temperature=0.9,\n",
    ")\n",
    "\n",
    "poem_3 = completion.choices[0].message.content\n",
    "\n",
    "print(\"\")\n",
    "print(\"Third poem:\")\n",
    "print(poem_3[:200] + \"...\" if len(poem_3) > 200 else poem_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In message 1, a forbidden word was detected: False\n",
      "In message 2, a forbidden word was detected: False\n",
      "In message 3, a forbidden word was detected: True\n"
     ]
    }
   ],
   "source": [
    "await workload.async_run(\n",
    "    messages=[\n",
    "        # Low probability of forbidden words.\n",
    "        lab.Message(\n",
    "            id=\"poem_1\",\n",
    "            content=poem_1,\n",
    "        ),\n",
    "        # High probability of forbidden words.\n",
    "        lab.Message(\n",
    "            id=\"poem_2\",\n",
    "            content=poem_2,\n",
    "        ),\n",
    "        # Forbidden words should be present.\n",
    "        lab.Message(\n",
    "            id=\"poem_3\",\n",
    "            content=poem_3,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Let's see the results\n",
    "for i in range(1, 4):\n",
    "    print(\n",
    "        f\"In message {i}, a forbidden word was detected: {workload.results['poem_'+str(i)]['regex_check'].value}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further\n",
    "\n",
    "Try implementing more complex jobs, such as a job that uses a machine learning model to classify messages, or a job that uses a NLP model to extract entities from messages.\n",
    "\n",
    "And why note opening a pull request to add your job to the phospho lab workload? We would love to see what you come up with!\n",
    "\n",
    "You want to have such analysis on your own LLM app, in real time? Check out the cloud hosted version of phospho, available on [phospho.ai](https://phospho.ai)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
